{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2ea64fb3-084e-4467-90ce-f3f6356cd3c3",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    },
    "tags": []
   },
   "source": [
    "[![Binder](https://mybinder.org/badge_logo.svg)](https://mybinder.org/v2/gh/stefmolin/pandas-workshop/main?urlpath=lab/tree/notebooks/2-data_wrangling.ipynb) [![View slides in browser](https://img.shields.io/badge/view-slides-orange?logo=reveal.js&logoColor=white)](https://stefmolin.github.io/pandas-workshop/slides/html/workshop.slides.html#/section-2)\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03ad7f69-c3e9-4ce8-a044-fd12502fd622",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "# Section 2: Data Wrangling\n",
    "\n",
    "To prepare our data for analysis, we need to perform data wrangling. In this section, we will learn how to clean and reformat data (e.g., renaming columns and fixing data type mismatches), restructure/reshape it, and enrich it (e.g., discretizing columns, calculating aggregations, and combining data sources)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1acd617-c093-4406-9ea8-61289e29e12c",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "## Data cleaning\n",
    "\n",
    "In this section, we will take a look at creating, renaming, and dropping columns; type conversion; and sorting &ndash; all of which make our analysis easier. We will be working with the 2019 Yellow Taxi Trip Data provided by NYC Open Data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c91ca2ea-c35b-455d-bbc9-312b47c864e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>vendorid</th>\n",
       "      <th>tpep_pickup_datetime</th>\n",
       "      <th>tpep_dropoff_datetime</th>\n",
       "      <th>passenger_count</th>\n",
       "      <th>trip_distance</th>\n",
       "      <th>ratecodeid</th>\n",
       "      <th>store_and_fwd_flag</th>\n",
       "      <th>pulocationid</th>\n",
       "      <th>dolocationid</th>\n",
       "      <th>payment_type</th>\n",
       "      <th>fare_amount</th>\n",
       "      <th>extra</th>\n",
       "      <th>mta_tax</th>\n",
       "      <th>tip_amount</th>\n",
       "      <th>tolls_amount</th>\n",
       "      <th>improvement_surcharge</th>\n",
       "      <th>total_amount</th>\n",
       "      <th>congestion_surcharge</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>2019-10-23T16:39:42.000</td>\n",
       "      <td>2019-10-23T17:14:10.000</td>\n",
       "      <td>1</td>\n",
       "      <td>7.93</td>\n",
       "      <td>1</td>\n",
       "      <td>N</td>\n",
       "      <td>138</td>\n",
       "      <td>170</td>\n",
       "      <td>1</td>\n",
       "      <td>29.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>7.98</td>\n",
       "      <td>6.12</td>\n",
       "      <td>0.3</td>\n",
       "      <td>47.90</td>\n",
       "      <td>2.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2019-10-23T16:32:08.000</td>\n",
       "      <td>2019-10-23T16:45:26.000</td>\n",
       "      <td>1</td>\n",
       "      <td>2.00</td>\n",
       "      <td>1</td>\n",
       "      <td>N</td>\n",
       "      <td>11</td>\n",
       "      <td>26</td>\n",
       "      <td>1</td>\n",
       "      <td>10.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.3</td>\n",
       "      <td>12.30</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2019-10-23T16:08:44.000</td>\n",
       "      <td>2019-10-23T16:21:11.000</td>\n",
       "      <td>1</td>\n",
       "      <td>1.36</td>\n",
       "      <td>1</td>\n",
       "      <td>N</td>\n",
       "      <td>163</td>\n",
       "      <td>162</td>\n",
       "      <td>1</td>\n",
       "      <td>9.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>2.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.3</td>\n",
       "      <td>15.80</td>\n",
       "      <td>2.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>2019-10-23T16:22:44.000</td>\n",
       "      <td>2019-10-23T16:43:26.000</td>\n",
       "      <td>1</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1</td>\n",
       "      <td>N</td>\n",
       "      <td>170</td>\n",
       "      <td>163</td>\n",
       "      <td>1</td>\n",
       "      <td>13.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>4.32</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.3</td>\n",
       "      <td>21.62</td>\n",
       "      <td>2.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>2019-10-23T16:45:11.000</td>\n",
       "      <td>2019-10-23T16:58:49.000</td>\n",
       "      <td>1</td>\n",
       "      <td>1.96</td>\n",
       "      <td>1</td>\n",
       "      <td>N</td>\n",
       "      <td>163</td>\n",
       "      <td>236</td>\n",
       "      <td>1</td>\n",
       "      <td>10.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.3</td>\n",
       "      <td>15.30</td>\n",
       "      <td>2.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   vendorid     tpep_pickup_datetime    tpep_dropoff_datetime   \n",
       "0         2  2019-10-23T16:39:42.000  2019-10-23T17:14:10.000  \\\n",
       "1         1  2019-10-23T16:32:08.000  2019-10-23T16:45:26.000   \n",
       "2         2  2019-10-23T16:08:44.000  2019-10-23T16:21:11.000   \n",
       "3         2  2019-10-23T16:22:44.000  2019-10-23T16:43:26.000   \n",
       "4         2  2019-10-23T16:45:11.000  2019-10-23T16:58:49.000   \n",
       "\n",
       "   passenger_count  trip_distance  ratecodeid store_and_fwd_flag   \n",
       "0                1           7.93           1                  N  \\\n",
       "1                1           2.00           1                  N   \n",
       "2                1           1.36           1                  N   \n",
       "3                1           1.00           1                  N   \n",
       "4                1           1.96           1                  N   \n",
       "\n",
       "   pulocationid  dolocationid  payment_type  fare_amount  extra  mta_tax   \n",
       "0           138           170             1         29.5    1.0      0.5  \\\n",
       "1            11            26             1         10.5    1.0      0.5   \n",
       "2           163           162             1          9.5    1.0      0.5   \n",
       "3           170           163             1         13.0    1.0      0.5   \n",
       "4           163           236             1         10.5    1.0      0.5   \n",
       "\n",
       "   tip_amount  tolls_amount  improvement_surcharge  total_amount   \n",
       "0        7.98          6.12                    0.3         47.90  \\\n",
       "1        0.00          0.00                    0.3         12.30   \n",
       "2        2.00          0.00                    0.3         15.80   \n",
       "3        4.32          0.00                    0.3         21.62   \n",
       "4        0.50          0.00                    0.3         15.30   \n",
       "\n",
       "   congestion_surcharge  \n",
       "0                   2.5  \n",
       "1                   0.0  \n",
       "2                   2.5  \n",
       "3                   2.5  \n",
       "4                   2.5  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "taxis = pd.read_csv('../data/2019_Yellow_Taxi_Trip_Data.csv')\n",
    "taxis.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d65aa6c3-092a-4ed9-95aa-57e8ec41e131",
   "metadata": {},
   "source": [
    "*Source: [NYC Open Data](https://data.cityofnewyork.us/Transportation/2019-Yellow-Taxi-Trip-Data/2upf-qytp) collected via [SODA](https://dev.socrata.com/foundry/data.cityofnewyork.us/2upf-qytp).*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79315a59-bc5b-4bd2-a25a-8f2de24217e2",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "### Dropping columns\n",
    "Let's start by dropping the ID columns and the `store_and_fwd_flag` column, which we won't be using."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e782b52c-dc8c-4aac-ba6d-f3b3cd7b5f2c",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['vendorid', 'ratecodeid', 'store_and_fwd_flag', 'pulocationid',\n",
       "       'dolocationid'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask = taxis.columns.str.contains('id$|store_and_fwd_flag', regex=True)\n",
    "columns_to_drop = taxis.columns[mask]\n",
    "columns_to_drop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bc0652f8-87af-43dd-82d0-07ba120b05f8",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tpep_pickup_datetime</th>\n",
       "      <th>tpep_dropoff_datetime</th>\n",
       "      <th>passenger_count</th>\n",
       "      <th>trip_distance</th>\n",
       "      <th>payment_type</th>\n",
       "      <th>fare_amount</th>\n",
       "      <th>extra</th>\n",
       "      <th>mta_tax</th>\n",
       "      <th>tip_amount</th>\n",
       "      <th>tolls_amount</th>\n",
       "      <th>improvement_surcharge</th>\n",
       "      <th>total_amount</th>\n",
       "      <th>congestion_surcharge</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019-10-23T16:39:42.000</td>\n",
       "      <td>2019-10-23T17:14:10.000</td>\n",
       "      <td>1</td>\n",
       "      <td>7.93</td>\n",
       "      <td>1</td>\n",
       "      <td>29.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>7.98</td>\n",
       "      <td>6.12</td>\n",
       "      <td>0.3</td>\n",
       "      <td>47.90</td>\n",
       "      <td>2.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019-10-23T16:32:08.000</td>\n",
       "      <td>2019-10-23T16:45:26.000</td>\n",
       "      <td>1</td>\n",
       "      <td>2.00</td>\n",
       "      <td>1</td>\n",
       "      <td>10.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.3</td>\n",
       "      <td>12.30</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2019-10-23T16:08:44.000</td>\n",
       "      <td>2019-10-23T16:21:11.000</td>\n",
       "      <td>1</td>\n",
       "      <td>1.36</td>\n",
       "      <td>1</td>\n",
       "      <td>9.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>2.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.3</td>\n",
       "      <td>15.80</td>\n",
       "      <td>2.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2019-10-23T16:22:44.000</td>\n",
       "      <td>2019-10-23T16:43:26.000</td>\n",
       "      <td>1</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1</td>\n",
       "      <td>13.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>4.32</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.3</td>\n",
       "      <td>21.62</td>\n",
       "      <td>2.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2019-10-23T16:45:11.000</td>\n",
       "      <td>2019-10-23T16:58:49.000</td>\n",
       "      <td>1</td>\n",
       "      <td>1.96</td>\n",
       "      <td>1</td>\n",
       "      <td>10.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.3</td>\n",
       "      <td>15.30</td>\n",
       "      <td>2.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      tpep_pickup_datetime    tpep_dropoff_datetime  passenger_count   \n",
       "0  2019-10-23T16:39:42.000  2019-10-23T17:14:10.000                1  \\\n",
       "1  2019-10-23T16:32:08.000  2019-10-23T16:45:26.000                1   \n",
       "2  2019-10-23T16:08:44.000  2019-10-23T16:21:11.000                1   \n",
       "3  2019-10-23T16:22:44.000  2019-10-23T16:43:26.000                1   \n",
       "4  2019-10-23T16:45:11.000  2019-10-23T16:58:49.000                1   \n",
       "\n",
       "   trip_distance  payment_type  fare_amount  extra  mta_tax  tip_amount   \n",
       "0           7.93             1         29.5    1.0      0.5        7.98  \\\n",
       "1           2.00             1         10.5    1.0      0.5        0.00   \n",
       "2           1.36             1          9.5    1.0      0.5        2.00   \n",
       "3           1.00             1         13.0    1.0      0.5        4.32   \n",
       "4           1.96             1         10.5    1.0      0.5        0.50   \n",
       "\n",
       "   tolls_amount  improvement_surcharge  total_amount  congestion_surcharge  \n",
       "0          6.12                    0.3         47.90                   2.5  \n",
       "1          0.00                    0.3         12.30                   0.0  \n",
       "2          0.00                    0.3         15.80                   2.5  \n",
       "3          0.00                    0.3         21.62                   2.5  \n",
       "4          0.00                    0.3         15.30                   2.5  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "taxis = taxis.drop(columns=columns_to_drop)\n",
    "taxis.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6581776-8391-41a3-a7fa-c65af402da77",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "source": [
    "*Tip: Another way to do this is to select the columns we want to keep: `taxis.loc[:,~mask]`.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23cc920e-4af6-456b-a0ce-87ade2b189ac",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "### Renaming columns\n",
    "\n",
    "Next, let's rename the datetime columns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "32ec2dc4-c8c3-424d-ae36-d732907b9f59",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['pickup', 'dropoff', 'passenger_count', 'trip_distance', 'payment_type',\n",
       "       'fare_amount', 'extra', 'mta_tax', 'tip_amount', 'tolls_amount',\n",
       "       'improvement_surcharge', 'total_amount', 'congestion_surcharge'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "taxis = taxis.rename(\n",
    "    columns={\n",
    "        'tpep_pickup_datetime': 'pickup', \n",
    "        'tpep_dropoff_datetime': 'dropoff'\n",
    "    }\n",
    ")\n",
    "taxis.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d74d21a8-d733-4afa-a140-29ccdcd83b46",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "### Type conversion\n",
    "\n",
    "Notice anything off with the data types?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b5ff546c-4a66-4102-b947-1d9147e89369",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pickup                    object\n",
       "dropoff                   object\n",
       "passenger_count            int64\n",
       "trip_distance            float64\n",
       "payment_type               int64\n",
       "fare_amount              float64\n",
       "extra                    float64\n",
       "mta_tax                  float64\n",
       "tip_amount               float64\n",
       "tolls_amount             float64\n",
       "improvement_surcharge    float64\n",
       "total_amount             float64\n",
       "congestion_surcharge     float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "taxis.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa644cbb-24dd-4a62-a350-f773c54c50fe",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "Both `pickup` and `dropoff` should be stored as datetimes. Let's fix this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "01299409-aace-4d41-bea5-7bd40a85e620",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pickup                   datetime64[ns]\n",
       "dropoff                  datetime64[ns]\n",
       "passenger_count                   int64\n",
       "trip_distance                   float64\n",
       "payment_type                      int64\n",
       "fare_amount                     float64\n",
       "extra                           float64\n",
       "mta_tax                         float64\n",
       "tip_amount                      float64\n",
       "tolls_amount                    float64\n",
       "improvement_surcharge           float64\n",
       "total_amount                    float64\n",
       "congestion_surcharge            float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "taxis[['pickup', 'dropoff']] = \\\n",
    "    taxis[['pickup', 'dropoff']].apply(pd.to_datetime)\n",
    "taxis.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "837ea457-45d8-4dae-aa0e-746be381f4da",
   "metadata": {},
   "source": [
    "*Tip: There are other ways to perform type conversion. For numeric values, we can use the `pd.to_numeric()` function, and we will see the `astype()` method, which is a more generic method, a little later.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a8fafca-8cf2-4402-ab34-758dabe955e2",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "### Creating new columns\n",
    "\n",
    "Let's calculate the following for each row:\n",
    "\n",
    "1. elapsed time of the trip\n",
    "2. the tip percentage\n",
    "3. the total taxes, tolls, fees, and surcharges\n",
    "4. the average speed of the taxi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "644ba83f-f834-4296-971e-5e7b07b955a8",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "taxis = taxis.assign(\n",
    "    elapsed_time=lambda x: x.dropoff - x.pickup, # 1\n",
    "    cost_before_tip=lambda x: x.total_amount - x.tip_amount,\n",
    "    tip_pct=lambda x: x.tip_amount / x.cost_before_tip, # 2\n",
    "    fees=lambda x: x.cost_before_tip - x.fare_amount, # 3\n",
    "    avg_speed=lambda x: x.trip_distance.div(\n",
    "        x.elapsed_time.dt.total_seconds() / 60 / 60\n",
    "    ) # 4\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d2cabea-d370-4ea9-951a-a22290fe182f",
   "metadata": {},
   "source": [
    "*Tip: New to `lambda` functions? These small, anonymous functions can receive multiple arguments, but can only contain one expression (the return value). You will see these a lot in pandas code. Read more about them [here](https://realpython.com/python-lambda/).*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0b2af8a-0727-4e08-a07d-64ddb73a71dd",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "Our new columns get added to the right:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ec0a2df8-4f40-4bb0-8cd8-0f558d218fd6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pickup</th>\n",
       "      <th>dropoff</th>\n",
       "      <th>passenger_count</th>\n",
       "      <th>trip_distance</th>\n",
       "      <th>payment_type</th>\n",
       "      <th>fare_amount</th>\n",
       "      <th>extra</th>\n",
       "      <th>mta_tax</th>\n",
       "      <th>tip_amount</th>\n",
       "      <th>tolls_amount</th>\n",
       "      <th>improvement_surcharge</th>\n",
       "      <th>total_amount</th>\n",
       "      <th>congestion_surcharge</th>\n",
       "      <th>elapsed_time</th>\n",
       "      <th>cost_before_tip</th>\n",
       "      <th>tip_pct</th>\n",
       "      <th>fees</th>\n",
       "      <th>avg_speed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019-10-23 16:39:42</td>\n",
       "      <td>2019-10-23 17:14:10</td>\n",
       "      <td>1</td>\n",
       "      <td>7.93</td>\n",
       "      <td>1</td>\n",
       "      <td>29.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>7.98</td>\n",
       "      <td>6.12</td>\n",
       "      <td>0.3</td>\n",
       "      <td>47.9</td>\n",
       "      <td>2.5</td>\n",
       "      <td>0 days 00:34:28</td>\n",
       "      <td>39.92</td>\n",
       "      <td>0.1999</td>\n",
       "      <td>10.42</td>\n",
       "      <td>13.804642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019-10-23 16:32:08</td>\n",
       "      <td>2019-10-23 16:45:26</td>\n",
       "      <td>1</td>\n",
       "      <td>2.00</td>\n",
       "      <td>1</td>\n",
       "      <td>10.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.3</td>\n",
       "      <td>12.3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0 days 00:13:18</td>\n",
       "      <td>12.30</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>1.80</td>\n",
       "      <td>9.022556</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               pickup             dropoff  passenger_count  trip_distance   \n",
       "0 2019-10-23 16:39:42 2019-10-23 17:14:10                1           7.93  \\\n",
       "1 2019-10-23 16:32:08 2019-10-23 16:45:26                1           2.00   \n",
       "\n",
       "   payment_type  fare_amount  extra  mta_tax  tip_amount  tolls_amount   \n",
       "0             1         29.5    1.0      0.5        7.98          6.12  \\\n",
       "1             1         10.5    1.0      0.5        0.00          0.00   \n",
       "\n",
       "   improvement_surcharge  total_amount  congestion_surcharge    elapsed_time   \n",
       "0                    0.3          47.9                   2.5 0 days 00:34:28  \\\n",
       "1                    0.3          12.3                   0.0 0 days 00:13:18   \n",
       "\n",
       "   cost_before_tip  tip_pct   fees  avg_speed  \n",
       "0            39.92   0.1999  10.42  13.804642  \n",
       "1            12.30   0.0000   1.80   9.022556  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "taxis.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15049dfd-dd9e-4365-8ecf-0a74f5fe3498",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "source": [
    "Some things to note:\n",
    "- We used `lambda` functions to 1) avoid typing `taxis` repeatedly and 2) be able to access the `cost_before_tip` and `elapsed_time` columns in the same method that we create them.\n",
    "- To create a single new column, we can also use `df['new_col'] = <values>`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1ebce53-9f31-4aa0-806d-a1a9fa43ece1",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "### Sorting by values\n",
    "\n",
    "We can use the `sort_values()` method to sort based on any number of columns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "77dbdd94-e6b7-4fb9-b6b1-718633b0a38a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pickup</th>\n",
       "      <th>dropoff</th>\n",
       "      <th>passenger_count</th>\n",
       "      <th>trip_distance</th>\n",
       "      <th>payment_type</th>\n",
       "      <th>fare_amount</th>\n",
       "      <th>extra</th>\n",
       "      <th>mta_tax</th>\n",
       "      <th>tip_amount</th>\n",
       "      <th>tolls_amount</th>\n",
       "      <th>improvement_surcharge</th>\n",
       "      <th>total_amount</th>\n",
       "      <th>congestion_surcharge</th>\n",
       "      <th>elapsed_time</th>\n",
       "      <th>cost_before_tip</th>\n",
       "      <th>tip_pct</th>\n",
       "      <th>fees</th>\n",
       "      <th>avg_speed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5997</th>\n",
       "      <td>2019-10-23 15:55:19</td>\n",
       "      <td>2019-10-23 16:08:25</td>\n",
       "      <td>6</td>\n",
       "      <td>1.58</td>\n",
       "      <td>2</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>14.3</td>\n",
       "      <td>2.5</td>\n",
       "      <td>0 days 00:13:06</td>\n",
       "      <td>14.3</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.3</td>\n",
       "      <td>7.236641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>443</th>\n",
       "      <td>2019-10-23 15:56:59</td>\n",
       "      <td>2019-10-23 16:04:33</td>\n",
       "      <td>6</td>\n",
       "      <td>1.46</td>\n",
       "      <td>2</td>\n",
       "      <td>7.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>11.8</td>\n",
       "      <td>2.5</td>\n",
       "      <td>0 days 00:07:34</td>\n",
       "      <td>11.8</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.3</td>\n",
       "      <td>11.577093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8722</th>\n",
       "      <td>2019-10-23 15:57:33</td>\n",
       "      <td>2019-10-23 16:03:34</td>\n",
       "      <td>6</td>\n",
       "      <td>0.62</td>\n",
       "      <td>1</td>\n",
       "      <td>5.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>10.5</td>\n",
       "      <td>2.5</td>\n",
       "      <td>0 days 00:06:01</td>\n",
       "      <td>9.8</td>\n",
       "      <td>0.071429</td>\n",
       "      <td>4.3</td>\n",
       "      <td>6.182825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4198</th>\n",
       "      <td>2019-10-23 15:57:38</td>\n",
       "      <td>2019-10-23 16:05:07</td>\n",
       "      <td>6</td>\n",
       "      <td>1.18</td>\n",
       "      <td>1</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>12.3</td>\n",
       "      <td>2.5</td>\n",
       "      <td>0 days 00:07:29</td>\n",
       "      <td>11.3</td>\n",
       "      <td>0.088496</td>\n",
       "      <td>4.3</td>\n",
       "      <td>9.461024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8238</th>\n",
       "      <td>2019-10-23 15:58:31</td>\n",
       "      <td>2019-10-23 16:29:29</td>\n",
       "      <td>6</td>\n",
       "      <td>3.23</td>\n",
       "      <td>2</td>\n",
       "      <td>19.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>23.8</td>\n",
       "      <td>2.5</td>\n",
       "      <td>0 days 00:30:58</td>\n",
       "      <td>23.8</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.3</td>\n",
       "      <td>6.258342</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  pickup             dropoff  passenger_count  trip_distance   \n",
       "5997 2019-10-23 15:55:19 2019-10-23 16:08:25                6           1.58  \\\n",
       "443  2019-10-23 15:56:59 2019-10-23 16:04:33                6           1.46   \n",
       "8722 2019-10-23 15:57:33 2019-10-23 16:03:34                6           0.62   \n",
       "4198 2019-10-23 15:57:38 2019-10-23 16:05:07                6           1.18   \n",
       "8238 2019-10-23 15:58:31 2019-10-23 16:29:29                6           3.23   \n",
       "\n",
       "      payment_type  fare_amount  extra  mta_tax  tip_amount  tolls_amount   \n",
       "5997             2         10.0    1.0      0.5         0.0           0.0  \\\n",
       "443              2          7.5    1.0      0.5         0.0           0.0   \n",
       "8722             1          5.5    1.0      0.5         0.7           0.0   \n",
       "4198             1          7.0    1.0      0.5         1.0           0.0   \n",
       "8238             2         19.5    1.0      0.5         0.0           0.0   \n",
       "\n",
       "      improvement_surcharge  total_amount  congestion_surcharge   \n",
       "5997                    0.3          14.3                   2.5  \\\n",
       "443                     0.3          11.8                   2.5   \n",
       "8722                    0.3          10.5                   2.5   \n",
       "4198                    0.3          12.3                   2.5   \n",
       "8238                    0.3          23.8                   2.5   \n",
       "\n",
       "        elapsed_time  cost_before_tip   tip_pct  fees  avg_speed  \n",
       "5997 0 days 00:13:06             14.3  0.000000   4.3   7.236641  \n",
       "443  0 days 00:07:34             11.8  0.000000   4.3  11.577093  \n",
       "8722 0 days 00:06:01              9.8  0.071429   4.3   6.182825  \n",
       "4198 0 days 00:07:29             11.3  0.088496   4.3   9.461024  \n",
       "8238 0 days 00:30:58             23.8  0.000000   4.3   6.258342  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "taxis.sort_values(['passenger_count', 'pickup'], ascending=[False, True]).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8d98a7c-7f12-43b7-9450-f0c0fa3162d3",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "To pick out the largest/smallest rows, use `nlargest()` / `nsmallest()` instead. Looking at the 3 trips with the longest elapsed time, we see some possible data integrity issues:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e1a26519-acb9-49e5-af1c-f5b055413bf8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pickup</th>\n",
       "      <th>dropoff</th>\n",
       "      <th>passenger_count</th>\n",
       "      <th>trip_distance</th>\n",
       "      <th>payment_type</th>\n",
       "      <th>fare_amount</th>\n",
       "      <th>extra</th>\n",
       "      <th>mta_tax</th>\n",
       "      <th>tip_amount</th>\n",
       "      <th>tolls_amount</th>\n",
       "      <th>improvement_surcharge</th>\n",
       "      <th>total_amount</th>\n",
       "      <th>congestion_surcharge</th>\n",
       "      <th>elapsed_time</th>\n",
       "      <th>cost_before_tip</th>\n",
       "      <th>tip_pct</th>\n",
       "      <th>fees</th>\n",
       "      <th>avg_speed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7576</th>\n",
       "      <td>2019-10-23 16:52:51</td>\n",
       "      <td>2019-10-24 16:51:44</td>\n",
       "      <td>1</td>\n",
       "      <td>3.75</td>\n",
       "      <td>1</td>\n",
       "      <td>17.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>21.8</td>\n",
       "      <td>2.5</td>\n",
       "      <td>0 days 23:58:53</td>\n",
       "      <td>21.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.3</td>\n",
       "      <td>0.156371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6902</th>\n",
       "      <td>2019-10-23 16:51:42</td>\n",
       "      <td>2019-10-24 16:50:22</td>\n",
       "      <td>1</td>\n",
       "      <td>11.19</td>\n",
       "      <td>2</td>\n",
       "      <td>39.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>41.3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0 days 23:58:40</td>\n",
       "      <td>41.3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.8</td>\n",
       "      <td>0.466682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4975</th>\n",
       "      <td>2019-10-23 16:18:51</td>\n",
       "      <td>2019-10-24 16:17:30</td>\n",
       "      <td>1</td>\n",
       "      <td>0.70</td>\n",
       "      <td>2</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>11.3</td>\n",
       "      <td>2.5</td>\n",
       "      <td>0 days 23:58:39</td>\n",
       "      <td>11.3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.3</td>\n",
       "      <td>0.029194</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  pickup             dropoff  passenger_count  trip_distance   \n",
       "7576 2019-10-23 16:52:51 2019-10-24 16:51:44                1           3.75  \\\n",
       "6902 2019-10-23 16:51:42 2019-10-24 16:50:22                1          11.19   \n",
       "4975 2019-10-23 16:18:51 2019-10-24 16:17:30                1           0.70   \n",
       "\n",
       "      payment_type  fare_amount  extra  mta_tax  tip_amount  tolls_amount   \n",
       "7576             1         17.5    1.0      0.5         0.0           0.0  \\\n",
       "6902             2         39.5    1.0      0.5         0.0           0.0   \n",
       "4975             2          7.0    1.0      0.5         0.0           0.0   \n",
       "\n",
       "      improvement_surcharge  total_amount  congestion_surcharge   \n",
       "7576                    0.3          21.8                   2.5  \\\n",
       "6902                    0.3          41.3                   0.0   \n",
       "4975                    0.3          11.3                   2.5   \n",
       "\n",
       "        elapsed_time  cost_before_tip  tip_pct  fees  avg_speed  \n",
       "7576 0 days 23:58:53             21.8      0.0   4.3   0.156371  \n",
       "6902 0 days 23:58:40             41.3      0.0   1.8   0.466682  \n",
       "4975 0 days 23:58:39             11.3      0.0   4.3   0.029194  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "taxis.nlargest(3, 'elapsed_time')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbe64c0c-41ab-4fd0-99b0-4f97790c87b8",
   "metadata": {},
   "source": [
    "### [Exercise 2.1](./workbook.ipynb#Exercise-2.1)\n",
    "\n",
    "##### Read in the meteorite data from the `Meteorite_Landings.csv` file, rename the `mass (g)` column to `mass`, and drop all the latitude and longitude columns. Sort the result by mass in descending order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62bd241b-c87a-41e4-b87f-7a2336f4903e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Complete this exercise in the workbook.ipynb file\n",
    "# Click on `Exercise 2.1` above to open the workbook.ipynb file\n",
    "\n",
    "# WARNING: if you complete the exercise here, your cell numbers\n",
    "# for the rest of the training might not match the slides"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97d61c46-b1f4-4531-8a2c-0ac8fcce6007",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "## Working with the index\n",
    "\n",
    "So far, we haven't really worked with the index because it's just been a row number; however, we can change the values we have in the index to access additional features of the pandas library."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cacbf64c-6356-4a2d-8a86-bd143d42914d",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "### Setting and sorting the index\n",
    "\n",
    "Currently, we have a RangeIndex, but we can switch to a DatetimeIndex by specifying a datetime column when calling `set_index()`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "223e2254-fef2-463f-841b-7b62e04cab4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "taxis = taxis.set_index('pickup')\n",
    "taxis.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e150b7a-cc6c-4b2a-a32c-13513e1fd518",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "Since we have a sample of the full dataset, let's sort the index to order by pickup time:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10477bf0-2d83-478c-8f9a-f15ba363b74c",
   "metadata": {},
   "outputs": [],
   "source": [
    "taxis = taxis.sort_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1c718db-b445-4290-b5bc-6afa51e45eac",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "source": [
    "*Tip: `taxis.sort_index(axis=1)` will sort the columns by name. The `axis` parameter is present throughout the pandas library: `axis=0` targets rows and `axis=1` targets columns.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b44074fe-6b74-4a2d-80b0-e5ed7fc7c9f6",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "We can now select ranges from our data based on the datetime the same way we did with row numbers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "825b2083-236c-4cfe-957d-4242619c659d",
   "metadata": {},
   "outputs": [],
   "source": [
    "taxis['2019-10-23 07:45':'2019-10-23 08']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c88bc8bb-a159-4347-84f5-654315facd1e",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "When not specifying a range, we use `loc[]`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fef82610-a9ca-47f3-b8f9-fca6cb8215c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "taxis.loc['2019-10-23 08']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0684e96e-6c5e-4405-8103-92ae722d9c3e",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "### Resetting the index\n",
    "\n",
    "We will be working with time series later this section, but sometimes we want to reset our index to row numbers and restore the columns. We can make `pickup` a column again with the `reset_index()` method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18a6c75b-fa89-4602-b9df-e18ea51d73b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "taxis = taxis.reset_index()\n",
    "taxis.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "569bcb48-b6bb-4e6c-9cc2-bc352047fb3e",
   "metadata": {},
   "source": [
    "### [Exercise 2.2](./workbook.ipynb#Exercise-2.2)\n",
    "\n",
    "##### Using the meteorite data from the `Meteorite_Landings.csv` file, update the `year` column to only contain the year, convert it to a numeric data type, and create a new column indicating whether the meteorite was observed falling before 1970. Set the index to the `id` column and extract all the rows with IDs between 10,036 and 10,040 (inclusive) with `loc[]`.\n",
    "\n",
    "###### **Hint 1**: Use `year.str.slice()` to grab a substring.\n",
    "\n",
    "###### **Hint 2**: Make sure to sort the index before using `loc[]` to select the range.\n",
    "\n",
    "###### **Bonus**: There's a data entry error in the `year` column. Can you find it? (Don't spend too much time on this.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef0097f4-18cb-4778-9118-cf89a39d9447",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Complete this exercise in the workbook.ipynb file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0c55eab-4901-4b05-9bf5-c2c0f6e1bda4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Click on `Exercise 2.2` above to open the workbook.ipynb file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c06312d7-838d-45c0-b093-f263ae3f9290",
   "metadata": {},
   "outputs": [],
   "source": [
    "# WARNING: if you complete the exercise here, your cell numbers\n",
    "# for the rest of the training might not match the slides"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25a31c80-88f8-4f4d-9192-80a7bf7e9689",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "## Reshaping data\n",
    "\n",
    "The taxi dataset we have be working with is in a format conducive to an analysis. This isn't always the case. Let's now take a look at the TSA traveler throughput data, which compares 2021 throughput to the same day in 2020 and 2019:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9fc17ff-40a4-4e01-b56a-fea6ed3ca471",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "tsa = pd.read_csv('../data/tsa_passenger_throughput.csv', parse_dates=['Date'])\n",
    "tsa.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43a2f0b0-affe-4ec4-906c-26401b750dc0",
   "metadata": {},
   "source": [
    "*Source: [TSA.gov](https://www.tsa.gov/coronavirus/passenger-throughput)*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71419100-c9d2-4e8d-a0e3-440d0d9ebded",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "First, we will lowercase the column names and take the first word (e.g., `2021` for `2021 Traveler Throughput`) to make this easier to work with:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdaa7ddd-57f4-41ca-b8ff-24d93d44f0b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "tsa = tsa.rename(columns=lambda x: x.lower().split()[0])\n",
    "tsa.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a39b842-3f40-4951-9a38-7dfd492ef608",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "source": [
    "Now, we can work on reshaping it."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc0b0c08-5cb6-4523-9dcc-4ea9a7e2607f",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "### Melting\n",
    "\n",
    "Melting helps convert our data into long format. Now, we have all the traveler throughput numbers in a single column:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebcfe696-5e4c-49e9-b281-1b7722cad24b",
   "metadata": {},
   "outputs": [],
   "source": [
    "tsa_melted = tsa.melt(\n",
    "    id_vars='date', # column that uniquely identifies a row (can be multiple)\n",
    "    var_name='year', # name for the new column created by melting\n",
    "    value_name='travelers' # name for new column containing values from melted columns\n",
    ")\n",
    "tsa_melted.sample(5, random_state=1) # show some random entries"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91ad2a4f-fd5f-4de6-b974-e37e6119b1f7",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "To convert this into a time series of traveler throughput, we need to replace the year in the `date` column with the one in the `year` column. Otherwise, we are marking prior years' numbers with the wrong year."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ad04dde-d03b-4a32-9a47-6b1a388a8169",
   "metadata": {},
   "outputs": [],
   "source": [
    "tsa_melted = tsa_melted.assign(\n",
    "    date=lambda x: pd.to_datetime(x.year + x.date.dt.strftime('-%m-%d'))\n",
    ")\n",
    "tsa_melted.sample(5, random_state=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28a312aa-f671-4df7-8e09-ea65ba7d6d70",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "This leaves us with some null values (the dates that aren't present in the dataset):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f415932-fe42-4e11-a8ac-521c7612147e",
   "metadata": {},
   "outputs": [],
   "source": [
    "tsa_melted.sort_values('date').tail(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "323970e9-0e9c-46f1-8910-a630fbd4d1b3",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "source": [
    "These can be dropped with the `dropna()` method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0ed0555-2467-4966-9cfb-31ff5982c0bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "tsa_melted = tsa_melted.dropna()\n",
    "tsa_melted.sort_values('date').tail(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a77b4fc-265e-42d8-ae27-689e3f7f8dc6",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "### Pivoting\n",
    "\n",
    "Using the melted data, we can pivot the data to compare TSA traveler throughput on specific days across years:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5deb2bd9-e4eb-4775-bbf1-b483c56edf16",
   "metadata": {},
   "outputs": [],
   "source": [
    "tsa_pivoted = tsa_melted\\\n",
    "    .query('date.dt.month == 3 and date.dt.day <= 10')\\\n",
    "    .assign(day_in_march=lambda x: x.date.dt.day)\\\n",
    "    .pivot(index='year', columns='day_in_march', values='travelers')\n",
    "tsa_pivoted"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "370ed66f-5b39-4adf-ae0d-651c4ae1981b",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "source": [
    "**Important**: We aren't covering the `unstack()` and `stack()` methods, which are additional ways to pivot and melt, respectively. These come in handy when we have a multi-level index (e.g., if we ran `set_index()` with more than one column). More information can be found [here](https://pandas.pydata.org/pandas-docs/stable/user_guide/reshaping.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e292be99-e3d6-403c-abce-56efa8b1948d",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "### Transposing\n",
    "\n",
    "The `T` attribute provides a quick way to flip rows and columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8a7bb2d-77c0-461b-9963-224b5bd633d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "tsa_pivoted.T"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65da6408-d946-4420-8fec-327094bf46e9",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "### Merging\n",
    "\n",
    "We typically observe changes in air travel around the holidays, so adding information about the dates in the TSA dataset provides more context. The `holidays.csv` file contains a few major holidays in the United States:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df6a13e1-af80-4d5e-9aa6-24495d7197cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "holidays = pd.read_csv('../data/holidays.csv', parse_dates=True, index_col='date')\n",
    "holidays.loc['2019']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0832a27-605c-48bd-b564-0901c2796b90",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "Merging the holidays with the TSA traveler throughput data will provide more context for our analysis:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "367b9ccb-04f6-4400-88b2-ce548990bb6f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tsa_melted_holidays = tsa_melted\\\n",
    "    .merge(holidays, left_on='date', right_index=True, how='left')\\\n",
    "    .sort_values('date')\n",
    "tsa_melted_holidays.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29efc7c8-f2c6-4a28-a36f-25e9da612d14",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "source": [
    "*Tip: There are many parameters for this method, so be sure to check out the [documentation](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.merge.html). To append rows, take a look at the `pd.concat()` function.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d79f677-5759-4790-9004-cb1a6361a0a8",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "We can take this a step further by marking a few days before and after each holiday as part of the holiday. This would make it easier to compare holiday travel across years and look for any uptick in travel around the holidays:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a589df8f-5870-41ea-b4c1-e413fa76ad31",
   "metadata": {},
   "outputs": [],
   "source": [
    "tsa_melted_holiday_travel = tsa_melted_holidays.assign(\n",
    "    holiday=lambda x:\n",
    "        x.holiday\\\n",
    "            .fillna(method='ffill', limit=1)\\\n",
    "            .fillna(method='bfill', limit=2)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb5a331c-143a-4b3e-bb90-9d948da4d148",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "source": [
    "*Tip: Check out the [documentation](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.fillna.html) for the full list of functionality available with the `fillna()` method.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c86a8f0-124b-4837-9c09-21923fbcb926",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "Notice that we now have values for the day after each holiday and the two days prior. Thanksgiving in 2019 was on November 28th, so the 26th, 27th, and 29th were filled. Since we are only replacing null values, we don't override Christmas Day with the forward fill of Christmas Eve:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c895269f-37b5-4246-974a-d8a91730f346",
   "metadata": {},
   "outputs": [],
   "source": [
    "tsa_melted_holiday_travel.query(\n",
    "    'year == \"2019\" and '\n",
    "    '(holiday == \"Thanksgiving\" or holiday.str.contains(\"Christmas\"))'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84597dd2-780e-451c-8263-c02fdadb857b",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "## Aggregations and grouping\n",
    "\n",
    "After reshaping and cleaning our data, we can perform aggregations to summarize it in a variety of ways. In this section, we will explore using pivot tables, crosstabs, and group by operations to aggregate the data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "350010f2-30ac-4167-8aa6-41e71933ef74",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "### Pivot tables\n",
    "We can build a pivot table to compare holiday travel across the years in our dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "944749f0-d9e1-4a6e-ad15-c8f33e737080",
   "metadata": {},
   "outputs": [],
   "source": [
    "tsa_melted_holiday_travel.pivot_table(\n",
    "    index='year', columns='holiday', \n",
    "    values='travelers', aggfunc='sum'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a189e47-9347-4922-a345-471206d8192c",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "We can use the `pct_change()` method on this result to see which holiday travel periods saw the biggest change in travel:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad480312-626f-401b-93d3-0ffd6a6392bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "tsa_melted_holiday_travel.pivot_table(\n",
    "    index='year', columns='holiday', \n",
    "    values='travelers', aggfunc='sum'\n",
    ").pct_change()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30a2f712-13e2-4f84-a6aa-d234b8d65dff",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "Let's make one last pivot table with column and row subtotals, along with some formatting improvements. First, we set a display option for all floats:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33a98f21-ea62-432c-8f7f-ee0d542b155b",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.float_format', '{:,.0f}'.format)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5ccd3b9-2179-45ac-85a2-6b57f220b1ed",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "Next, we group together Christmas Eve and Christmas Day, likewise for New Year's Eve and New Year's Day, and create the pivot table:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98ab467c-f26d-436d-9f73-7ea35fc5fa86",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "tsa_melted_holiday_travel.assign(\n",
    "    holiday=lambda x: np.where(\n",
    "        x.holiday.str.contains('Christmas|New Year', regex=True), \n",
    "        x.holiday.str.replace('Day|Eve', '', regex=True).str.strip(), \n",
    "        x.holiday\n",
    "    )\n",
    ").pivot_table(\n",
    "    index='year', columns='holiday', \n",
    "    values='travelers', aggfunc='sum', \n",
    "    margins=True, margins_name='Total'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "145150cd-3fde-48c1-87d4-857c858d8494",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "Before moving on, let's reset the display option:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55e95c66-fb5b-4ee2-a1ce-8ead82a2715a",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.reset_option('display.float_format')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa6dc364-f48f-482b-86be-152d6d16961f",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "source": [
    "*Tip: Read more about options in the documentation [here](https://pandas.pydata.org/pandas-docs/stable/user_guide/options.html).*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87b782d9-3404-4e68-b0eb-cdc201393cb3",
   "metadata": {},
   "source": [
    "### [Exercise 2.3](./workbook.ipynb#Exercise-2.3)\n",
    "\n",
    "##### Using the meteorite data from the `Meteorite_Landings.csv` file, create a pivot table that shows both the number of meteorites and the 95th percentile of meteorite mass for those that were found versus observed falling per year from 2005 through 2009 (inclusive). Hint: Be sure to convert the `year` column to a number as we did in the previous exercise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86157a08-5379-4ffd-af34-da2ef32a2633",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Complete this exercise in the workbook.ipynb file\n",
    "# Click on `Exercise 2.3` above to open the workbook.ipynb file\n",
    "\n",
    "# WARNING: if you complete the exercise here, your cell numbers\n",
    "# for the rest of the training might not match the slides"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d988e70-5547-4a15-ab6c-b0eade8fb8b9",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "### Crosstabs\n",
    "The `pd.crosstab()` function provides an easy way to create a frequency table. Here, we count the number of low-, medium-, and high-volume travel days per year, using the `pd.cut()` function to create three travel volume bins of equal width:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27d17ef2-b8be-43df-aab8-a2d7f5d228f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.crosstab(\n",
    "    index=pd.cut(\n",
    "        tsa_melted_holiday_travel.travelers, \n",
    "        bins=3, labels=['low', 'medium', 'high']\n",
    "    ),\n",
    "    columns=tsa_melted_holiday_travel.year,\n",
    "    rownames=['travel_volume']\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7aceb604-c3e9-4b1a-b62d-ada3f86ad897",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "source": [
    "*Tip: The `pd.cut()` function can also be used to specify custom bin ranges. For equal-sized bins based on quantiles, use the `pd.qcut()` function instead.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb00efed-de93-4adf-92b2-4d88ae07565e",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "Note that the `pd.crosstab()` function supports other aggregations provided you pass in the data to aggregate as `values` and specify the aggregation with `aggfunc`. You can also add subtotals and normalize the data. See the [documentation](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.crosstab.html) for more information."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08c2a7b6-7e1d-4c91-9360-888335dc26df",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "### Group by operations\n",
    "Rather than perform aggregations, like `mean()` or `describe()`, on the full dataset at once, we can perform these calculations per group by first calling `groupby()`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "638ecd3d-48e9-4fea-96eb-1a6be49bb43d",
   "metadata": {},
   "outputs": [],
   "source": [
    "tsa_melted_holiday_travel.groupby('year').describe(include=np.number)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72053860-fe4d-4e16-971c-91dedd14f522",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "Groups can also be used to perform separate calculations per subset of the data. For example, we can find the highest-volume travel day per year using `rank()`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c5f7495-7d00-4b7b-a3b6-76c1f47457c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "tsa_melted_holiday_travel.assign(\n",
    "    travel_volume_rank=lambda x: x.groupby('year').travelers.rank(ascending=False)\n",
    ").sort_values(['travel_volume_rank', 'year']).head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc57c29a-cd58-4ff5-9c69-9e8f68b05168",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "The previous two examples called a single method on the grouped data, but using the `agg()` method we can specify any number of them:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce014d66-ba8b-4537-b8f1-9548dccab5b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "tsa_melted_holiday_travel.assign(\n",
    "    holiday_travelers=lambda x: np.where(~x.holiday.isna(), x.travelers, np.nan),\n",
    "    non_holiday_travelers=lambda x: np.where(x.holiday.isna(), x.travelers, np.nan),\n",
    "    year=lambda x: pd.to_numeric(x.year)\n",
    ").select_dtypes(include='number').groupby('year').agg(['mean', 'std'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7484d71-3091-4d8f-9e2d-53b07871ebaf",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "source": [
    "*Tip: The `select_dtypes()` method makes it possible to select columns by their data type. We can specify the data types to `exclude` and/or `include`.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f012232-0ac4-48ce-9ae3-ed936657ef24",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "In addition, we can specify which aggregations to perform on each column:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3080e40b-4ac7-4395-a76e-e773d16901fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "tsa_melted_holiday_travel.assign(\n",
    "    holiday_travelers=lambda x: np.where(~x.holiday.isna(), x.travelers, np.nan),\n",
    "    non_holiday_travelers=lambda x: np.where(x.holiday.isna(), x.travelers, np.nan)\n",
    ").groupby('year').agg({\n",
    "    'holiday_travelers': ['mean', 'std'], \n",
    "    'holiday': ['nunique', 'count']\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73fc6c25-387e-4ff6-aaa0-7e212f766c2e",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "We are only scratching the surface; some additional functionalities to be aware of include the following:\n",
    "- We can group by multiple columns &ndash; this creates a hierarchical index.\n",
    "- Groups can be excluded from calculations with the `filter()` method.\n",
    "- We can group on content in the index using the `level` or `name` parameters e.g., `groupby(level=0)` or `groupby(name='year')`.\n",
    "- We can group by date ranges if we use a `pd.Grouper()` object."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd7409b7-6eec-4ed0-8a09-c8b6333ef75d",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "source": [
    "Be sure to check out the [documentation](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.groupby.html) for more details."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f35e0f4b-916e-4a99-ba99-4d4a02d4d884",
   "metadata": {},
   "source": [
    "### [Exercise 2.4](./workbook.ipynb#Exercise-2.4)\n",
    "\n",
    "##### Using the meteorite data from the `Meteorite_Landings.csv` file, compare summary statistics of the mass column for the meteorites that were found versus observed falling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32e4f6ff-a57c-4d50-9911-fd74b4522125",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Complete this exercise in the workbook.ipynb file\n",
    "# Click on `Exercise 2.4` above to open the workbook.ipynb file\n",
    "\n",
    "# WARNING: if you complete the exercise here, your cell numbers\n",
    "# for the rest of the training might not match the slides"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f39b28e-9c9b-4b97-93be-41ade4dcd8f8",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "## Time series\n",
    "\n",
    "When working with time series data, pandas provides us with additional functionality to not just compare the observations in our dataset, but to use their relationship in time to analyze the data. In this section, we will see a few such operations for selecting date/time ranges, calculating changes over time, performing window calculations, and resampling the data to different date/time intervals."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bb690d8-a77e-4dd7-a8ac-4a4fcfc3a156",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "### Selecting based on date and time\n",
    "\n",
    "Let's switch back to the `taxis` dataset, which has timestamps of pickups and dropoffs. First, we will set the `dropoff` column as the index and sort the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1556b7a-ccde-432b-81a9-8b2c80b67d68",
   "metadata": {},
   "outputs": [],
   "source": [
    "taxis = taxis.set_index('dropoff').sort_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef86c832-5ed4-4a86-8a84-93fb179b9df4",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "We saw earlier that we can slice on the datetimes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f41a0a74-0bc8-4649-8b86-f44cdfb1062a",
   "metadata": {},
   "outputs": [],
   "source": [
    "taxis['2019-10-24 12':'2019-10-24 13']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c286a4f6-54fc-409d-b10a-8f6ac2734347",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "We can also represent this range with shorthand. Note that we must use `loc[]` here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e6b26c9-4048-4207-8454-b9f018a56816",
   "metadata": {},
   "outputs": [],
   "source": [
    "taxis.loc['2019-10-24 12']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8705d663-67c8-4f6f-b3e9-52bceeea122f",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "source": [
    "However, if we want to look at this time range across days, we need another strategy."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78093e7d-ce53-424b-b484-820c4d98ace0",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "We can pull out the dropoffs that happened between a certain time range on *any* day with the `between_time()` method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "915f528c-639f-4b8b-99cc-9c83bb0cad4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "taxis.between_time('12:00', '13:00')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98520264-8284-414c-9c23-0c054af076f5",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "source": [
    "*Tip: The `at_time()` method can be used to extract all entries at a given time (e.g., 12:35:27).*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b6abd12-4ad3-47ed-be2f-c4a3bb6b1fbf",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "Finally, `head()` and `tail()` limit us to a number of rows, but we may be interested in rows within the first/last 2 hours (or any other time interval) of the data, in which case, we should use `first()` / `last()`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0e31dc9-dc86-4481-97b1-1cbb9d5490a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "taxis.first('2H')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f0c8566-4a05-4710-8146-773089a05a07",
   "metadata": {},
   "source": [
    "*Tip: Available date/time offsets can be found in the pandas documentation [here](https://pandas.pydata.org/pandas-docs/stable/user_guide/timeseries.html#dateoffset-objects).* "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8c0485e-4730-4124-8e71-493e7e9c45d6",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "For the rest of this section, we will be working with the TSA traveler throughput data. Let's start by setting the index to the `date` column:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a06c5b3-cb6b-4f02-9559-208fd94a78ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "tsa_melted_holiday_travel = tsa_melted_holiday_travel.set_index('date')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20ae3a50-f2f4-4880-8463-a16bb7932ba2",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "### Calculating change over time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a554fda-2363-4c87-b8f3-17773c511c43",
   "metadata": {},
   "outputs": [],
   "source": [
    "tsa_melted_holiday_travel.loc['2020'].assign(\n",
    "    one_day_change=lambda x: x.travelers.diff(),\n",
    "    seven_day_change=lambda x: x.travelers.diff(7),\n",
    ").head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4938d37c-9e59-4c5b-88c1-32709c0b68d9",
   "metadata": {},
   "source": [
    "*Tip: To perform operations other than subtraction, take a look at the `shift()` method. It also makes it possible to perform operations across columns.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86e9b6a3-7547-4d38-93ec-1a27e64615cf",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "### Resampling\n",
    "We can use resampling to aggregate time series data to a new frequency:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0093c590-342a-4add-9999-0fb063cfa5e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "tsa_melted_holiday_travel['2019':'2021-Q1'].select_dtypes(include='number')\\\n",
    "    .resample('Q').agg(['sum', 'mean', 'std'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c169d6c8-a744-462a-bfbb-a5cadd29eca9",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "### Window calculations\n",
    "\n",
    "Window calculations are similar to group by calculations except the group over which the calculation is performed isn't static &ndash; it can move or expand. Pandas provides functionality for constructing a variety of windows, including moving/rolling windows, expanding windows (e.g., cumulative sum or mean up to the current date in a time series), and exponentially weighted moving windows (to weight closer observations more than further ones). We will only look at rolling and expanding calculations here."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acdebc2e-20f9-4963-9aeb-90a6d91db14e",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "Performing a window calculation is very similar to a group by calculation &ndash; we first define the window, and then we specify the aggregation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d83c0d2e-16db-49de-b15b-ba30792a89e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "tsa_melted_holiday_travel.loc['2020'].assign(\n",
    "    **{\n",
    "        '7D MA': lambda x: x.rolling('7D').travelers.mean(),\n",
    "        'YTD mean': lambda x: x.expanding().travelers.mean()\n",
    "      }\n",
    ").head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dab1843-9179-415f-be5b-1ebafaef3690",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "To understand what's happening, it's best to visualize the original data and the result, so here's a sneak peek of plotting with pandas. First, some setup to embed SVG plots in the notebook:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da84fa52-b2a9-4ab8-9d6d-643a3b43b94e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib_inline\n",
    "from utils import mpl_svg_config\n",
    "\n",
    "matplotlib_inline.backend_inline.set_matplotlib_formats(\n",
    "    'svg', # output images using SVG format\n",
    "    **mpl_svg_config('section-2') # optional: configure metadata\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81e00227-a79d-464f-bbbf-318992b6a5a4",
   "metadata": {},
   "source": [
    "*Tip: For most use cases, only the first argument is necessary &ndash; we will discuss the second argument in more detail in the next section.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "474adada-c6c6-4306-ab85-a23a6bebaca7",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "Now, we call the `plot()` method to visualize the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e31834c-3299-44b0-8ac3-6939b91b9be0",
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = tsa_melted_holiday_travel.loc['2020'].assign(\n",
    "    **{\n",
    "        '7D MA': lambda x: x.rolling('7D').travelers.mean(),\n",
    "        'YTD mean': lambda x: x.expanding().travelers.mean()\n",
    "      }\n",
    ").plot(title='2020 TSA Traveler Throughput', ylabel='travelers', alpha=0.8)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fe90855-8228-4cf6-9c8b-375b416071b7",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "Other types of windows:\n",
    "- [exponentially weighted moving](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.ewm.html): use the `ewm()` method\n",
    "- [custom](https://pandas.pydata.org/docs/user_guide/window.html#window-custom-rolling-window): create a subclass of `pandas.api.indexers.BaseIndexer` or use a pre-built one in `pandas.api.indexers`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc18799b-77d4-4699-9967-9797d76d3539",
   "metadata": {},
   "source": [
    "### [Exercise 2.5](./workbook.ipynb#Exercise-2.5)\n",
    "\n",
    "##### Using the taxi trip data in the `2019_Yellow_Taxi_Trip_Data.csv` file, resample the data to an hourly frequency based on the dropoff time. Calculate the total `trip_distance`, `fare_amount`, `tolls_amount`, and `tip_amount`, then find the 5 hours with the most tips."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5ce22c9-ea36-4d60-b291-c67e1deeeabf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Complete this exercise in the workbook.ipynb file\n",
    "# Click on `Exercise 2.5` above to open the workbook.ipynb file"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94ab60e4-a8de-4453-8598-4112bb86f098",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "## Up Next: [Data Visualization](./3-data_visualization.ipynb)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
